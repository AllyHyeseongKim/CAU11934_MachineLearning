{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment10.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMukJNIwdK3G2DSxLoH3va0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AllyHyeseongKim/CAU11934_MachineLearning/blob/feature%2Fassignment10/assignment/10/assignment10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUL5PMpo3xb0",
        "colab_type": "text"
      },
      "source": [
        "# Assignment10: Multi-label classification using neural networks with a regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALBIU9KR33Y9",
        "colab_type": "text"
      },
      "source": [
        "## 1. Load the input data (csv file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wid6MPJ735VJ",
        "colab_type": "text"
      },
      "source": [
        "### Mount the google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxDJ0-24xu0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFxBfptArts-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-Cccwg2rv9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd ../content/gdrive/My Drive/Colab Notebooks/Machine Learning/assignment10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeGW-jTN3_3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9WsauyO4IAX",
        "colab_type": "text"
      },
      "source": [
        "### Load the Data\n",
        "\n",
        "Load a set of the data from the given `csv file` (`'mnist.csv'`) for training. \\\\\n",
        "Each row of the data consists of the `label`, $l$ and the `image pixel values`, $x$ in a `vector form`, where the `label` is one of the 10 digits from 0 to 9, $l \\in [0, 9]$. \\\\\n",
        "The `image` represents its associated `label` in the `grey scale` and the number of images is 10,000 and the size of each image is $28 \\times 28$, $x \\in \\mathbb{R}^{784}$. \\\\\n",
        "Consder the first `1,000 images` for `training` and the rest `9,000 images` for `testing`. \\\\\n",
        "`Normalize` the `intensity values` of each image so that they ranges from `0 to 1`. \\\\\n",
        "Plot the `images` that are loaded from `'mnist.csv'` file. \\\\"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dABXry9Br0Kq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "\n",
        "file_data   = \"mnist.csv\"\n",
        "handle_file = open(file_data, \"r\")\n",
        "data        = handle_file.readlines()\n",
        "handle_file.close()\n",
        "\n",
        "size_row    = 28    # height of the image\n",
        "size_col    = 28    # width of the image\n",
        "\n",
        "num_image   = len(data)\n",
        "count       = 0     # count for the number of images\n",
        "\n",
        "#\n",
        "# normalize the values of the input data to be [0, 1]\n",
        "#\n",
        "def normalize(data):\n",
        "\n",
        "    data_normalized = (data - min(data)) / (max(data) - min(data))\n",
        "\n",
        "    return(data_normalized)\n",
        "\n",
        "#\n",
        "# example of distance function between two vectors x and y\n",
        "#\n",
        "def distance(x, y):\n",
        "\n",
        "    d = (x - y) ** 2\n",
        "    s = cp.sum(d)\n",
        "    # r = np.sqrt(s)\n",
        "\n",
        "    return(s)\n",
        "\n",
        "#\n",
        "# make a matrix each column of which represents an images in a vector form\n",
        "# split the first 1,000 images for training and the rest 9,000 images for testing\n",
        "#\n",
        "num_train_image = 1000\n",
        "num_test_image = 9000\n",
        "\n",
        "np_list_image_train  = np.empty((size_row * size_col, num_train_image), dtype=float)\n",
        "np_list_label_train  = np.empty(num_train_image, dtype=int)\n",
        "np_list_image_test  = np.empty((size_row * size_col, num_test_image), dtype=float)\n",
        "np_list_label_test  = np.empty(num_test_image, dtype=int)\n",
        "\n",
        "for line in data[:num_train_image]:\n",
        "\n",
        "    line_data   = line.split(',')\n",
        "    label       = int(line_data[0])\n",
        "    im_vector_train   = np.asfarray(line_data[1:])\n",
        "    im_vector_train   = normalize(im_vector_train)\n",
        "\n",
        "    np_list_label_train[count]       = label\n",
        "    np_list_image_train[:, count]    = im_vector_train\n",
        "\n",
        "    count += 1\n",
        "\n",
        "count = 0\n",
        "for line in data[num_train_image:]:\n",
        "    line_data   = line.split(',')\n",
        "    label        = int(line_data[0])\n",
        "    im_vector_test   = np.asfarray(line_data[1:])\n",
        "    im_vector_test   = normalize(im_vector_test)\n",
        "\n",
        "    np_list_label_test[count]       = label\n",
        "    np_list_image_test[:, count]    = im_vector_test\n",
        "\n",
        "    count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty8trt1fMxAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_image_train = cp.array(np_list_image_train)\n",
        "list_label_train = cp.array(np_list_label_train)\n",
        "list_image_test = cp.array(np_list_image_test)\n",
        "list_label_test = cp.array(np_list_label_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2dqXYEPjHFr",
        "colab_type": "text"
      },
      "source": [
        "## 2. Neural Network Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjN8pxYcjVMf",
        "colab_type": "text"
      },
      "source": [
        "```mermaid\n",
        "(input layer : x)  --> (first hidden layer : y)  -->  (output layer : h)\n",
        "```\n",
        "\n",
        "```mermaid\n",
        "(x)  -- fully connected : u -->  (y_)  -- sigmoid -->  (y)  -- fully connected : v -->  (h_)  -- sigmoid -->  (h)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndUndTkSB49E",
        "colab_type": "text"
      },
      "source": [
        "Build a `neural network` for the `multi-label classification` with `10 labels`. \\\\\n",
        "Construct a `neural network` with `4 layers` including the `input layer` and the `output layer`. \\\\\n",
        "Each `hidden layer` is defined by a `logistic unit`. \\\\\n",
        "A `logistic unit` consists of a `fully connected layer` with a `bias` followed by the `sigmoid activation function`. \\\\\n",
        " \\\\\n",
        "The `dimension` of each layer is defined by: \\\\\n",
        "`Input layer` : 784 (+ a `bias`) \\\\\n",
        "`First hidden layer` : 196 (+ a `bias`) \\\\\n",
        "`Output layer` : 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX8wzzKLPcAO",
        "colab_type": "text"
      },
      "source": [
        "### 2.1. Generate the Fully Connected Layer\n",
        "\n",
        "Define the following `fully connected layer` with a `bias`.\n",
        "\n",
        "\\begin{equation*}\n",
        "(output \\ layer) = 1\\times\\theta_0^t + (input \\ layer)_1\\times\\theta_1^t + (input \\ layer)_2\\times\\theta_2^t + ... + (input \\ layer)_{num \\ input}^t, \\quad\\text{where, $t =$ (the number of the iteration of the layer)}\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wodvsIriCLBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fully_connected(num_input, num_output, weight, input_layer, num_image):\n",
        "    output_layer  = cp.empty((num_image, num_output), dtype=float)\n",
        "    input_reshaped = cp.ones((num_input + 1, num_image), dtype=float)\n",
        "    input_reshaped[1:] = input_layer\n",
        "    weight_reshaped = weight.reshape(num_output, num_input + 1)\n",
        "    output_layer = cp.matmul(weight_reshaped, input_reshaped)\n",
        "    return output_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp5HbqtQ5U9C",
        "colab_type": "text"
      },
      "source": [
        "### 2.2. Generate the Sigmoid Function as an Activation Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFozuJ3e5Yi_",
        "colab_type": "text"
      },
      "source": [
        "#### Generate the `sigmoid function`\n",
        "\n",
        "Define the following `sigmoid fuction` as an `activation fuction`.\n",
        "\n",
        "\\begin{equation*}\n",
        "\\sigma(z) = \\frac{1}{1 + exp(-z)} \\\\\n",
        "\\sigma'(z) = \\sigma(z)(1 - \\sigma(z)) \\\\\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF_EH1XyYihP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(input_layer, num_image):\n",
        "    output_layer  = np.empty((len(input_layer[0]), num_image), dtype=np.float128)\n",
        "    for i in range(num_image):\n",
        "        for j in range(len(input_layer[0])):\n",
        "            output_layer[j][i] = 1/(1 + np.exp(-input_layer[i][j]))\n",
        "    return output_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_dYkIe1CwwP",
        "colab_type": "text"
      },
      "source": [
        "### 2.3. Generate the `Objective Function`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PIj7i3vDSvN",
        "colab_type": "text"
      },
      "source": [
        "Define the following `objective function`.\n",
        "\n",
        "\\begin{equation*}\n",
        "J(\\theta) = \\frac{1}{m}​\\sum_{i = 1}^m​\\sum_{k = 0}^9​(−l_k^{(i)}​log(h_k^{(i)}​)−(1−l_k^{(i)}​)log(1−h_k^{(i)}​)) + \\frac{\\lambda}{2n}\\sum_{j = 1}^n\\theta_j^2, \\\\\n",
        "\\text{where,}\\quad \\theta_j \\text{ denotes a model parametter where $j = 1, 2, ..., n$}, \\theta = (u, v), \\\\\n",
        "\\lambda \\text{ is a control parameter for the regularization based on the $L_2^2$-norm (weight decay)}, \\\\\n",
        "n\\text{ is the total number of all the model parameters over the entire neural network, therefore, $n = 2$}, \\\\\n",
        "\\text{ and $h_k^{(i)}$ denotes the $k^{th}$ element of the output layer for $i^{th}$ sample data.}\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs8CJmQVWA1e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJoGKM5hfzyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def objective(output_layer, num_image, label):\n",
        "    errors = []\n",
        "    error = 0\n",
        "    for i in range(num_image):\n",
        "        for j in range(10):\n",
        "            error = error + ((-label[i]) * math.log(output_layer[j][i]) - (1 - label[i]) * math.log(1 - output_layer[j][i]))\n",
        "        errors.append(error)\n",
        "    return (1 / num_image) * sum(errors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cirfXRGhEcYF",
        "colab_type": "text"
      },
      "source": [
        "### 2.3. Generate the `Gradient Descent` (`Back-Propagation`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa7zkkL1DPfF",
        "colab_type": "text"
      },
      "source": [
        "Define the `learning rate`.\n",
        "\n",
        "\\begin{equation*}\n",
        "\\alpha  = 0.001\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFCrlBMrCLZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpyybBUmEz2W",
        "colab_type": "text"
      },
      "source": [
        "Define the following `gradient descent`.\n",
        "\n",
        "\\begin{equation*}\n",
        "\\theta_k^{(t + 1)} := \\theta_k^{(t)} - \\alpha\\frac{\\partial J(\\theta^{(t)})}{\\partial \\theta_k}, \\quad\\text{for all $k$}.\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwJHUNfKu3lG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient_descent(input_layer, output_layer, weight):\n",
        "    num_weight = len(weight)\n",
        "    num_input = len(input_layer)\n",
        "    num_output = len(output_layer)\n",
        "    input_reshaped = np.ones((num_input + 1, num_train_image), dtype=np.float128)\n",
        "    input_reshaped[1:] = input_layer\n",
        "    weight_reshaped = weight.reshape(num_output, num_input + 1)\n",
        "    weight_update = weight_reshaped\n",
        "    label_reshaped = np.empty((num_output, num_train_image), dtype=np.float128)\n",
        "    for i in range(num_output):\n",
        "        label_reshaped[i] = list_label_train\n",
        "    weight_update = weight_update - np.dot(learning_rate / num_train_image, np.matmul(output_layer-label_reshaped, np.transpose(input_reshaped)))\n",
        "    return weight_update.reshape(1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYzUFM4jq0Mx",
        "colab_type": "text"
      },
      "source": [
        "### 2.4. Compute the `Accuracy`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX_1DMDZq898",
        "colab_type": "text"
      },
      "source": [
        "Compute the following `accuracy` in `number (%)`.\n",
        "\\begin{equation}\n",
        "accuracy\\ (\\%) = \\frac{\\text{number of correct predictions}}{\\text{total number of predictions}} \\times 100\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD0X0W0WrLYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(output_layer, num_image, label):\n",
        "    num_correct_predict = 0\n",
        "    for i in range(num_image):\n",
        "        if np.argmax(output_layer[:, i]) == label[i]:\n",
        "            num_correct_predict = num_correct_predict + 1\n",
        "    return (num_correct_predict / num_image) * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTQ5fNon_luS",
        "colab_type": "text"
      },
      "source": [
        "### 2.4. `Train` and `Test` the input data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmCtCARLAJiS",
        "colab_type": "text"
      },
      "source": [
        "Define the `initial conditions` of `weights` $(\\theta_{0}^{(0)}, \\theta_{1}^{(0)}, \\theta_{2}^{(0)}, ..., \\theta_{28\\times28}^{(0)})$. \\\\\n",
        "The `weights` ar following a `normal distribution` $\\mathcal{N}(0, \\sigma^2)$ with `mean` 0 and `standard deviation` some number."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aw4kFwBGOgn",
        "colab_type": "text"
      },
      "source": [
        "Define the `standard deviation`. \\\\\n",
        "\n",
        "\\begin{equation*}\n",
        "\\sigma = 0.01\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE29KmutnDDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP0O-QmmYih8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize(num):\n",
        "    weight = np.random.randn(num)\n",
        "    return weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z63hYVN3VTGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight1 = np.empty((epoch, 785 * 196), dtype=np.float128)\n",
        "weight1[0] = initialize(785 * 196)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDvI8vJ8X9t3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight2 = np.empty((epoch, 197 * 49), dtype=np.float128)\n",
        "weight2[0] = initialize(197 * 49)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oDqtviQX-HT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight3 = np.empty((epoch, 50 * 10), dtype=np.float128)\n",
        "weight3[0] = initialize(50 * 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKT5lGy2A5V8",
        "colab_type": "text"
      },
      "source": [
        "`Train` the `train data` with the `Neural Network Architecture` above with the `gradient descent`. \\\\\n",
        "Find `optimal parameters` $\\theta$ using the `traing data` (the first `1,000 images`). \\\\\n",
        "`Test` the `test data` with the `Neural Network Architecture` above with the `obtained parameters` $\\theta$ from the `training process` using the `testing data` (the rest `9,000 images`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp9jnAk5lH8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input_layer_x = np.empty((784, num_train_image), dtype=np.float128)\n",
        "train_y = np.empty((num_train_image, 196), dtype=np.float128)\n",
        "train_hidden_layer_y = np.empty((196, num_train_image), dtype=np.float128)\n",
        "train_z = np.empty((num_train_image, 49), dtype=np.float128)\n",
        "train_hidden_layer_z = np.empty((49, num_train_image), dtype=np.float128)\n",
        "train_h = np.empty((num_train_image, 10), dtype=np.float128)\n",
        "train_output_layer_h = np.empty((10, num_train_image), dtype=np.float128)\n",
        "train_input_layer_x = list_image_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A3lchJ2pSx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_input_layer_x = np.empty((784, num_test_image), dtype=np.float128)\n",
        "test_y = np.empty((num_test_image, 196), dtype=np.float128)\n",
        "test_hidden_layer_y = np.empty((196, num_test_image), dtype=np.float128)\n",
        "test__z = np.empty((num_test_image, 49), dtype=np.float128)\n",
        "test_hidden_layer_z = np.empty((49, num_test_image), dtype=np.float128)\n",
        "test_h = np.empty((num_test_image, 10), dtype=np.float128)\n",
        "test_output_layer_h = np.empty((10, num_test_image), dtype=np.float128)\n",
        "test_input_layer_x = list_image_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miiukdoxnSQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = np.empty(epoch, dtype=np.float128)\n",
        "test_loss = np.empty(epoch, dtype=np.float128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZpaLijfp21X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_accuracy = np.empty(epoch, dtype=np.float128)\n",
        "test_accuracy = np.empty(epoch, dtype=np.float128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3o2M_mmjz3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(epoch):\n",
        "    train_y = fully_connected(784, 196, weight1[i], train_input_layer_x, num_train_image)\n",
        "    train_hidden_layer_y = sigmoid(train_y, num_train_image)\n",
        "    train_z = fully_connected(196, 49, weight2[i], train_hidden_layer_y, num_train_image)\n",
        "    train_hidden_layer_z = sigmoid(train_z, num_train_image)\n",
        "    train_h = fully_connected(49, 10, weight3[i], train_hidden_layer_z, num_train_image)\n",
        "    train_output_layer_h = sigmoid(train_h, num_train_image)\n",
        "\n",
        "    train_loss[i] = objective(train_output_layer_h, num_train_image, list_label_train)\n",
        "    train_accuracy[i] = accuracy(train_output_layer_h, num_train_image, list_label_train)\n",
        "\n",
        "    print(\"[\", i + 1, \"/\", epoch, \"]\", \"train loss: \", train_loss[i], \", train accuracy: \", train_accuracy[i])\n",
        "\n",
        "    test_y = fully_connected(784, 196, weight1[i], test_input_layer_x, num_test_image)\n",
        "    test_hidden_layer_y = sigmoid(test_y, num_test_image)\n",
        "    test_z = fully_connected(196, 49, weight2[i], test_hidden_layer_y, num_test_image)\n",
        "    test_hidden_layer_z = sigmoid(test_z, num_test_image)\n",
        "    test_h = fully_connected(49, 10, weight3[i], test_hidden_layer_z, num_test_image)\n",
        "    test_output_layer_h = sigmoid(test_h, num_test_image)\n",
        "\n",
        "    test_loss[i] = objective(test_output_layer_h, num_test_image, list_label_test)\n",
        "    test_accuracy[i] = accuracy(test_output_layer_h, num_test_image, list_label_test)\n",
        "\n",
        "    print(\"[\", i + 1, \"/\", epoch, \"]\", \"test loss: \", test_loss[i], \", test accuracy: \", test_accuracy[i])\n",
        "\n",
        "    if i < (epoch - 1):\n",
        "        weight3[i + 1] =  gradient_descent(train_hidden_layer_z, train_output_layer_h, weight3[i])\n",
        "        weight2[i + 1] = gradient_descent(train_hidden_layer_y, train_hidden_layer_z, weight2[i])\n",
        "        weight1[i + 1] = gradient_descent(train_input_layer_x, train_hidden_layer_y, weight1[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fVy9RdHvofq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot(list_label, list_image, i):\n",
        "    label       = list_label\n",
        "    im_vector   = list_image\n",
        "    im_matrix   = im_vector.reshape((size_row, size_col))\n",
        "    \n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.title(label)\n",
        "    plt.imshow(im_matrix, cmap='Greys', interpolation='None')\n",
        "\n",
        "    frame   = plt.gca()\n",
        "    frame.axes.get_xaxis().set_visible(False)\n",
        "    frame.axes.get_yaxis().set_visible(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eS9x-OPzhbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_correct = []\n",
        "test_miss = []\n",
        "for i in range(num_test_image):\n",
        "    if np.argmax(test_output_layer_h[:, i]) == list_label_test[i]:\n",
        "        test_correct.append(i)\n",
        "    else:\n",
        "        test_miss.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7KprHVQDhY3",
        "colab_type": "text"
      },
      "source": [
        "## 3. **Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqRkLfC5Dlpq",
        "colab_type": "text"
      },
      "source": [
        "### 3.1. **Plot the loss curve**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4ysZpDTDojS",
        "colab_type": "text"
      },
      "source": [
        "Plot the `training loss` at `every iteration` of `gradient descent` using the `training data` (the first `1,000 images`) (in `blue` color). \\\\\n",
        "Plot the `testing loss` at `every iteration` of `gradient descent` using the `testing data` (the rest `9,000 images`) in `red` color. \\\\\n",
        "The both `curves` should be presented in `one figure`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyyRWqECQaxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "x_cost1 = np.arange(0, epoch)\n",
        "x_cost2 = np.arange(0, epoch)\n",
        "plt.xlabel('t (iteration)')\n",
        "plt.ylabel('J(theta)')\n",
        "\n",
        "plt.plot(x_cost1, train_loss[:epoch], color = 'blue', label = 'training loss')\n",
        "plt.plot(x_cost2, test_loss[:epoch], color = 'red', label = 'testing loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMDeilIRDuS2",
        "colab_type": "text"
      },
      "source": [
        "### 3.2. **Plot the accuracy curve**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuqmpAX-w96y",
        "colab_type": "text"
      },
      "source": [
        "Plot the `training accuracy` (%) at `every iteration` of `gradient descent` using the `training data` (the first `1,000 images`) (in `blue` color). \\\\\n",
        "plot the `testing accuracy` (%) at `every iteration` of `gradient descent` using the `testing data` (the rest `9,000 images`) (in `red` color). \\\\\n",
        "The both `curves` should be presented in `one figure`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EpsSm9ow880",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.xlabel('t (iteration)')\n",
        "plt.ylabel('accuracy(%)')\n",
        "\n",
        "plt.plot(x_cost1, train_accuracy[:epoch], color = 'blue', label = 'training accuracy')\n",
        "plt.plot(x_cost2, test_accuracy[:epoch], color = 'red', label = 'testing accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADlDFzpL83CC",
        "colab_type": "text"
      },
      "source": [
        "### 3.3. **Plot the accuracy value**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLdK0PDL9Dgm",
        "colab_type": "text"
      },
      "source": [
        "Print the `final training accuracy` (%) using the `training data` (the first `1,000 images`). \\\\\n",
        "Print the `final testing accuracy` (%) using the `testing data` (the rest `9,000 images`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBP6Lc-h---a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Final training accuracy: \", train_accuracy[epoch - 1])\n",
        "print(\"Final testing accuracy: \", test_accuracy[epoch - 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wi-UAjz9Vr6",
        "colab_type": "text"
      },
      "source": [
        "### 3.4. **Plot the classification example**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnIjkdNZ9a5j",
        "colab_type": "text"
      },
      "source": [
        "Present `10 correctly classified testing images` with their `labels` at the title of each sub-figure in `2x5 array`. \\\\\n",
        "Present `10 misclassified testing images` with their misclassified `labels` at the title of each sub-figure in `2x5 array`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD1tHqyD_MM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1 = plt.figure(figsize=(8, 4))\n",
        "\n",
        "plot(np.argmax(test_output_layer_h[:, test_correct[0]]), list_image_test[:, test_correct[0]], 0)\n",
        "plot(np.argmax(test_output_layer_h[:, test_correct[1]]), list_image_test[:, test_correct[1]], 1)\n",
        "plot(np.argmax(test_output_layer_h[:, test_correct[2]]), list_image_test[:, test_correct[2]], 2)\n",
        "plot(np.argmax(test_output_layer_h[:, test_correct[3]]), list_image_test[:, test_correct[3]], 3)\n",
        "plot(np.argmax(test_output_layer_h[:, test_correct[4]]), list_image_test[:, test_correct[4]], 4)\n",
        "plot(np.argmax(test_output_layer_h[:, test_correct[5]]), list_image_test[:, test_correct[5]], 5)\n",
        "plot(np.argmax(test_output_layer_h[:, test_correct[6]]), list_image_test[:, test_correct[6]], 6)\n",
        "plot(np.argmax(test_output_layer_h[:, test_correct[7]]), list_image_test[:, test_correct[7]], 7)\n",
        "plot(np.argmax(test_output_layer_h[:, test_correct[8]]), list_image_test[:, test_correct[8]], 8)\n",
        "plot(np.argmax(test_output_layer_h[:, test_correct[9]]), list_image_test[:, test_correct[9]], 9)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Flu5s6Sn_Wqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1 = plt.figure(figsize=(8, 4))\n",
        "\n",
        "plot(np.argmax(test_output_layer_h[:, test_miss[0]]), list_image_test[:, test_miss[0]], 0)\n",
        "plot(np.argmax(test_output_layer_h[:, test_miss[1]]), list_image_test[:, test_miss[1]], 1)\n",
        "plot(np.argmax(test_output_layer_h[:, test_miss[2]]), list_image_test[:, test_miss[2]], 2)\n",
        "plot(np.argmax(test_output_layer_h[:, test_miss[3]]), list_image_test[:, test_miss[3]], 3)\n",
        "plot(np.argmax(test_output_layer_h[:, test_miss[4]]), list_image_test[:, test_miss[4]], 4)\n",
        "plot(np.argmax(test_output_layer_h[:, test_miss[5]]), list_image_test[:, test_miss[5]], 5)\n",
        "plot(np.argmax(test_output_layer_h[:, test_miss[6]]), list_image_test[:, test_miss[6]], 6)\n",
        "plot(np.argmax(test_output_layer_h[:, test_miss[7]]), list_image_test[:, test_miss[7]], 7)\n",
        "plot(np.argmax(test_output_layer_h[:, test_miss[8]]), list_image_test[:, test_miss[8]], 8)\n",
        "plot(np.argmax(test_output_layer_h[:, test_miss[9]]), list_image_test[:, test_miss[9]], 9)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxHHdgMtLsNf",
        "colab_type": "text"
      },
      "source": [
        "### 3.5. **`Testing` accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiXRP5pt7R8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}