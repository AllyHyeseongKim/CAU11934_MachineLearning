{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment04.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNkNf37AfuTmREJe+VPwEfa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AllyHyeseongKim/CAU11934_MachineLarning/blob/master/assignment/04/assignment04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKyssBeNINGO",
        "colab_type": "text"
      },
      "source": [
        "# Assignment04: Linear regression with multiple variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1CghtcAIi5A",
        "colab_type": "text"
      },
      "source": [
        "## 1. Load the input data (CSV file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIpyh88uImJ_",
        "colab_type": "text"
      },
      "source": [
        "### Mount the google drive "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqtiZAWNmUKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysII75CRkMIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd gdrive/My Drive/Colab Notebooks/Machine Learning/assignment04"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-64XTNAIq3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayDyfPQjjhac",
        "colab_type": "text"
      },
      "source": [
        "### Load the Data\n",
        "\n",
        "Load a set of data points $\\{ (x^{(i)}, y^{(i)}, z^{(i)}, h^{(i)}) \\}$ from the given `CSV file` (`'data_train.csv'`) for training. \\\\\n",
        "Print the set of points that are loaded from `'data_train.csv'` file. \\\\\n",
        "Load a set of data points $\\{ (x^{(i)}, y^{(i)}, z^{(i)}, h^{(i)}) \\}$ from the given `CSV file` (`'data_test.csv`) for testing. \\\\\n",
        "Print the set of points that are loaded from `'data_test.csv'` file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chVEImkgjvNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "z_train = []\n",
        "h_train = []\n",
        "\n",
        "with open('data_train.csv', newline='') as myfile:\n",
        "    reader  = csv.reader(myfile, delimiter=',')\n",
        "    ct = 1 \n",
        "    for i in reader:\n",
        "        x_train.append(float(i[0]))\n",
        "        y_train.append(float(i[1]))\n",
        "        z_train.append(float(i[2]))\n",
        "        h_train.append(float(i[3]))\n",
        "        m = ct\n",
        "        ct += 1\n",
        "\n",
        "x_test = []\n",
        "y_test = []\n",
        "z_test = []\n",
        "h_test = []\n",
        "\n",
        "with open('data_test.csv', newline='') as myfile:\n",
        "    reader  = csv.reader(myfile, delimiter=',')\n",
        "    ct = 1 \n",
        "    for i in reader:\n",
        "        x_test.append(float(i[0]))\n",
        "        y_test.append(float(i[1]))\n",
        "        z_test.append(float(i[2]))\n",
        "        h_test.append(float(i[3]))\n",
        "        ct += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGpMAEqlSwGW",
        "colab_type": "text"
      },
      "source": [
        "## 2. Generate the Linear Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUPi8bW-SyxY",
        "colab_type": "text"
      },
      "source": [
        "### Generate the `linear regression`\n",
        "\n",
        "Define the following `Linear Model`.\n",
        "\n",
        "\\begin{equation*}\n",
        "f_\\theta(x, y, z) = \\theta_0 + \\theta_1 x + \\theta_2 y + \\theta_3 z, \\quad\\quad \\text{where $\\theta = (\\theta_0, \\theta_1, \\theta_2, \\theta_3) $ and $\\theta_0, \\theta_1, \\theta_2, \\theta_3 \\in \\mathbb{R}$}\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n5JMkOuTlmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_regression(weight, offset):\n",
        "    y_linear_regression = []\n",
        "    for i in range(m):\n",
        "        y_linear_regression.append(offset + weight[0] * x_train[i] + weight[1] * y_train[i] + weight[2] * z_train[i])\n",
        "    return y_linear_regression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AunvzJ3TXMHf",
        "colab_type": "text"
      },
      "source": [
        "## 3. Generate the `Cost Function` with `Gradient Descent` method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYAa8TJlXOlI",
        "colab_type": "text"
      },
      "source": [
        "### Generate the `objective function`\n",
        "\n",
        "Define the following `objective function`.\n",
        "\n",
        "\\begin{equation*}\n",
        "J(\\theta_0, \\theta_1, \\theta_2, \\theta_3) = \\frac{1}{2m}\\sum_{i = 1}^m(\\theta_0 + \\theta_1x^{(i)} + \\theta_2y^{(i)} +\\theta_3z^{(i)} - h^{(i)})^2\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIw59zPIXhhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def objective_function(y_linear_regression, h):\n",
        "    error = []\n",
        "    for i in range(m):\n",
        "        error.append((y_linear_regression[i] - h[i]) ** 2)\n",
        "    return sum(error) / (2 * m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8vjQzHZX7Jr",
        "colab_type": "text"
      },
      "source": [
        "### Generate the `gradient descent`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzyGCrvrX9mM",
        "colab_type": "text"
      },
      "source": [
        "Define the following `gradient descent`.\n",
        "\n",
        "\\begin{equation*}\n",
        "\\theta_0^{(t+1)} := \\theta_0^{(t)} - \\alpha\\frac{1}{m}\\sum_{i = 1}^m(f_\\theta(x^{(i)}, y^{(i)}, z^{(i)}) - h^{(i)}) \\\\\n",
        "\\theta_1^{(t+1)} := \\theta_1^{(t)} - \\alpha\\frac{1}{m}\\sum_{i = 1}^m(f_\\theta(x^{(i)}, y^{(i)}, z^{(i)}) - h^{(i)})x^{(i)} \\\\\n",
        "\\theta_2^{(t+1)} := \\theta_1^{(t)} - \\alpha\\frac{1}{m}\\sum_{i = 1}^m(f_\\theta(x^{(i)}, y^{(i)}, z^{(i)}) - h^{(i)})y^{(i)} \\\\\n",
        "\\theta_3^{(t+1)} := \\theta_1^{(t)} - \\alpha\\frac{1}{m}\\sum_{i = 1}^m(f_\\theta(x^{(i)}, y^{(i)}, z^{(i)}) - h^{(i)})z^{(i)}\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwy_yTmjY7sz",
        "colab_type": "text"
      },
      "source": [
        "Define the `learning rate`.\n",
        "\n",
        "\\begin{equation*}\n",
        "\\alpha  = 0.000012\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlxPKqk2Y-t5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.000012"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOf-2UXgZKRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient_descent(weight, offset, y_linear_regression):\n",
        "    offset_error = []\n",
        "    weightPrime = []\n",
        "    for i in range(m):\n",
        "        offset_error.append(y_linear_regression[i] - h_train[i])\n",
        "    offset = offset - learning_rate * sum(offset_error) / m\n",
        "    weight_error = []\n",
        "    weight_error.append([])\n",
        "    weight_error.append([])\n",
        "    weight_error.append([])\n",
        "    for i in range(m):\n",
        "        weight_error[0].append((y_linear_regression[i] - h_train[i]) * x_train[i])\n",
        "        weight_error[1].append((y_linear_regression[i] - h_train[i]) * y_train[i])\n",
        "        weight_error[2].append((y_linear_regression[i] - h_train[i]) * z_train[i])\n",
        "    weightPrime.append(weight[0] - learning_rate * sum(weight_error[0]) / m)\n",
        "    weightPrime.append(weight[1] - learning_rate * sum(weight_error[1]) / m)\n",
        "    weightPrime.append(weight[2] - learning_rate * sum(weight_error[2]) / m)\n",
        "    return weightPrime, offset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE_FL8xuZ-g4",
        "colab_type": "text"
      },
      "source": [
        "## 4. `Train` the input data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9LjODtHaA0w",
        "colab_type": "text"
      },
      "source": [
        "Define the initial `weight`$(\\theta_1^{(0)}, \\theta_2^{(0)}, \\theta_3^{(0)})$ and `offset`$(\\theta_0^{(0)})$:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\theta_0^{(0)} = 2, \\theta_1^{(0)} = 2, \\theta_2^{(0)}  = 2, \\theta_3^{(0)}  = 2.\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq-4jv-0bGJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight = []\n",
        "weight.append([])\n",
        "offset = []\n",
        "weight[0].append(1)\n",
        "weight[0].append(1)\n",
        "weight[0].append(1)\n",
        "offset.append(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4oGOSV5ccW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cost_convergence = []\n",
        "theta_convergence = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRxqgnBnciY9",
        "colab_type": "text"
      },
      "source": [
        "`Train` the `input data` with the `linear regression` function above with the `gradient descent`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdAyjNt0clE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = m * 10\n",
        "h = []\n",
        "j = []\n",
        "i = 0\n",
        "# print(linear_regression(weight[0], offset[0]))\n",
        "# print(objective_function(linear_regression(weight[0], offset[0])))\n",
        "h.append(linear_regression(weight[i], offset[i]))\n",
        "j.append(objective_function(linear_regression(weight[i], offset[i]), h_train))\n",
        "# print(j)\n",
        "\n",
        "while i < epoch:\n",
        "    i = i + 1\n",
        "    '''\n",
        "    print(i)\n",
        "    print('weight: ', weight)\n",
        "    print('offset: ', offset)\n",
        "    print('j: ', j)\n",
        "    print('h: ', h)\n",
        "    '''\n",
        "    weight.append(gradient_descent(weight[i - 1], offset[i - 1], h[i - 1])[0])\n",
        "    offset.append(gradient_descent(weight[i - 1], offset[i - 1], h[i - 1])[1])\n",
        "    '''\n",
        "    print('weight: ', weight)\n",
        "    print('offset: ', offset)\n",
        "    print(i)\n",
        "    '''\n",
        "    h.append(linear_regression(weight[i], offset[i]))\n",
        "#    print(offset[i])\n",
        "#    print(round(j[i - 1], 2))\n",
        "    j.append(objective_function(linear_regression(weight[i], offset[i]), h_train))\n",
        "    if round(j[i], 0) == round(j[i - 1], 0):\n",
        "        cost_convergence.append(i)\n",
        "    if round(weight[i][0], 2) == round(weight[i - 1][0], 2):\n",
        "        if round(weight[i][1], 2) == round(weight[i - 1][1], 2):\n",
        "            if round(weight[i][2], 2) == round(weight[i - 1][2], 2):\n",
        "                if (round(offset[i], 2) == round(offset[i - 1], 2)):\n",
        "                    theta_convergence.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul7IYb0t3TZg",
        "colab_type": "text"
      },
      "source": [
        "## 5. `Test` the input data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuN6fa4k3Zsi",
        "colab_type": "text"
      },
      "source": [
        "`Evaluate` the inference using the `testing dataset` (`'data_test.csv'`). \\\\\n",
        "Use the `objective function` $J(\\theta_0, \\theta_1, \\theta_2, \\theta_3)$ for measuring the `dissimilarity` between the expected value and the inference using the testing data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJvih7jE37ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f_test = []\n",
        "j_test = []\n",
        "\n",
        "i = 0\n",
        "\n",
        "for i in range(m):\n",
        "    for i in range(m):\n",
        "        f_test.append(offset[i] + weight[i][0] * x_train[i] + weight[i][1] * y_train[i] + weight[i][2] * z_train[i])\n",
        "    j_test.append(objective_function(f_test, h_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbCglkxbmY4X",
        "colab_type": "text"
      },
      "source": [
        "## 6. **Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ14qi0JmcJh",
        "colab_type": "text"
      },
      "source": [
        "### 1. **Plot the estimated parameters using the training dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_-YgtVrm-lE",
        "colab_type": "text"
      },
      "source": [
        "Plot the `estimated parameters` $\\{ (\\theta_0, \\theta_1, \\theta_2, \\theta_3) \\}$ at `every iteration` of `gradient descent` until `onvergence` (in `black`, `red`, `green`, `blue` color, respectively).\n",
        "The `optimization` is performed using the `training dataset` (`'data_train.csv'`).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzTNYLOtqCFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize = (8, 8))\n",
        "x_out = np.arange(0, theta_convergence[0] + 1)\n",
        "plt.xlabel('t (iteration)')\n",
        "'''\n",
        "print(type(weight[0]))\n",
        "print(weight[:theta_convergence[0] + 1])\n",
        "print(weight[:theta_convergence[0] + 1][0])\n",
        "print(weight[0][:(theta_convergence[0] + 1)])\n",
        "'''\n",
        "plt.plot(x_out, offset[:theta_convergence[0] + 1], color = 'black')\n",
        "plt.plot(x_out, list(map(lambda x: x[0], weight[:theta_convergence[0] + 1])), color = 'red')\n",
        "plt.plot(x_out, list(map(lambda x: x[1], weight[:theta_convergence[0] + 1])), color = 'green')\n",
        "plt.plot(x_out, list(map(lambda x: x[2], weight[:theta_convergence[0] + 1])), color = 'blue')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjIaJi6amsmy",
        "colab_type": "text"
      },
      "source": [
        "### 2. **Plot the training error using the training dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI6O3XKPnkHB",
        "colab_type": "text"
      },
      "source": [
        "Plot the `training error` $J(\\theta_0, \\theta_1, \\theta_2, \\theta_3)$ at `every iteration` of `gradient descent` until `convergence` (in `blue` color)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_97iBLh1sL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize = (8, 8))\n",
        "x_out = np.arange(0, epoch + 1)\n",
        "plt.xlabel('t (iteration)')\n",
        "plt.plot(x_out, j, color = 'blue')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W5rNFFAm0UM",
        "colab_type": "text"
      },
      "source": [
        "### 3. **Plot the testing error using the testing dataset at every iteration of gradient descent until convergence**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l62_JvaSnuuO",
        "colab_type": "text"
      },
      "source": [
        "Plot the `testing error` $J(\\theta_0, \\theta_1, \\theta_2, \\theta_3)$ at `every iteration` of `gradient descent` until `convergence` (in `red` color)."
      ]
    }
  ]
}