{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment08.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/MRTcHNXpdwRlfWKzZbf0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AllyHyeseongKim/CAU11934_MachineLearning/blob/master/assignment/08/assignment08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUL5PMpo3xb0",
        "colab_type": "text"
      },
      "source": [
        "# Assignment08: Forward Propagation in the Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALBIU9KR33Y9",
        "colab_type": "text"
      },
      "source": [
        "## 1. Load the input data (text file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wid6MPJ735VJ",
        "colab_type": "text"
      },
      "source": [
        "### Mount the google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxDJ0-24xu0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFxBfptArts-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-Cccwg2rv9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd ../content/gdrive/My Drive/Colab Notebooks/Machine Learning/assignment08"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeGW-jTN3_3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9WsauyO4IAX",
        "colab_type": "text"
      },
      "source": [
        "### Load the Data\n",
        "\n",
        "Load a set of the data from the given `csv file` (`'mnist_test.txt'`) for training. \\\\\n",
        "Each row of the data consists of the `label` and the `image pixel values` in a `vector form`, where the `label` is one of the 10 digits from 0 to 9 and the `image` represents one of the 10 digits from 0 to 9 in grey scale and its size is 28x28. \\\\\n",
        "Plot the `images` that are loaded from `'mnist_test.csv'` file. \\\\"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VadCSLtn4h4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "file_data   = \"mnist_test.csv\"\n",
        "handle_file = open(file_data, \"r\")\n",
        "data        = handle_file.readlines()\n",
        "handle_file.close()\n",
        "\n",
        "size_row    = 28    # height of the image\n",
        "size_col    = 28    # width of the image\n",
        "\n",
        "num_image   = len(data)\n",
        "count       = 0     # count for the number of images\n",
        "\n",
        "#\n",
        "# make a matrix each column of which represents an images in a vector form \n",
        "#\n",
        "list_image  = np.empty((size_row * size_col, num_image), dtype=float)\n",
        "list_label  = np.empty(num_image, dtype=int)\n",
        "\n",
        "for line in data:\n",
        "\n",
        "    line_data   = line.split(',')\n",
        "    label       = line_data[0]\n",
        "    im_vector   = np.asfarray(line_data[1:])\n",
        "\n",
        "    list_label[count]       = label\n",
        "    list_image[:, count]    = im_vector    \n",
        "\n",
        "    count += 1\n",
        "\n",
        "# \n",
        "# plot first 100 images out of 10,000 with their labels\n",
        "# \n",
        "f1 = plt.figure(1)\n",
        "\n",
        "for i in range(100):\n",
        "\n",
        "    label       = list_label[i]\n",
        "    im_vector   = list_image[:, i]\n",
        "    im_matrix   = im_vector.reshape((size_row, size_col))\n",
        "\n",
        "    plt.subplot(10, 10, i+1)\n",
        "    plt.title(label)\n",
        "    plt.imshow(im_matrix, cmap='Greys', interpolation='None')\n",
        "\n",
        "    frame   = plt.gca()\n",
        "    frame.axes.get_xaxis().set_visible(False)\n",
        "    frame.axes.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhuiVZRKjAZD",
        "colab_type": "text"
      },
      "source": [
        "## 2. Average Image for Each Digit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9bnnCh2jOxX",
        "colab_type": "text"
      },
      "source": [
        "Take the `arithmatic average` of the `image data` with the `same label` for `each digit`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2dqXYEPjHFr",
        "colab_type": "text"
      },
      "source": [
        "## 3. Forward Propagation with Random Weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjN8pxYcjVMf",
        "colab_type": "text"
      },
      "source": [
        "Consider a `neural network` with a `fully connected layer` using a `logistic unit`. \\\\\n",
        "The `weights` of the `fully connected layer` are given by `random numbers` sampled from the `Normal distribution` $\\mathcal{N}(0, 1)$ with `mean` 0 and `standard deviation` 1. \\\\\n",
        "Compute the `average` of the `output` of the `neural network` using a `logistic unit` for the `images` of the `same label` for `each digit`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp5HbqtQ5U9C",
        "colab_type": "text"
      },
      "source": [
        "## 2. Generate the Logistic Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFozuJ3e5Yi_",
        "colab_type": "text"
      },
      "source": [
        "### Generate the `logistic regression`\n",
        "\n",
        "Define the following `logistic regression` with a `high dimensional function feature function`.\n",
        "\n",
        "\\begin{equation*}\n",
        "\\hat{h} = \\sigma(z) \\\\\n",
        "z = g(x, y; \\theta), \\quad\\text{where $g$ is a high dimensional function and $\\theta \\in \\mathbb{R}^{100}$} \\\\\n",
        "\\theta = (\\theta_{0, 0}, \\theta_{0, 1}, ..., \\theta_{9, 9}) \\\\\n",
        "g(x, y; \\theta) = \\sum_{i = 0}^9\\sum_{j = 0}^9\\theta_{i, j}x^iy^j \\\\\n",
        "\\sigma(z) = \\frac{1}{1 + exp(-z)} \\\\\n",
        "\\sigma'(z) = \\sigma(z)(1 - \\sigma(z)) \\\\\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Td7c0f-iHyK",
        "colab_type": "text"
      },
      "source": [
        "Define the `function` $g(x, y; \\theta)$:\n",
        "\\begin{equation}\n",
        "g(x, y; \\theta) = \\sum_{i = 0}^9\\sum_{j = 0}^9\\theta_{i, j}x^iy^j\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnAXhYwBeH2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def g(weight):\n",
        "    g = []\n",
        "    for i in range(m):\n",
        "        g_k = 0\n",
        "        for j in range(10):\n",
        "            for k in range(10):\n",
        "                g_k = g_k + weight[10 * j + k] * (x_train[i] ** j) * (y_train[i] ** k)\n",
        "        g.append(g_k)\n",
        "    return g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwEIlM7vEbQi",
        "colab_type": "text"
      },
      "source": [
        "Define the following `sigmoid function`.\n",
        "\n",
        "\\begin{equation*}\n",
        "\\hat{h} = \\sigma(z), \\text{ where }\n",
        "\\sigma(z) = \\frac{1}{1 + exp(-z)}, \\\\\n",
        "z = g(x, y; \\theta) = \\sum_{i = 0}^9\\sum_{j = 0}^9\\theta_{i, j}x^iy^j \\\\\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF_EH1XyYihP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logistic_regression(weight):\n",
        "    y_logistic_regression = []\n",
        "    z = g(weight)\n",
        "    for i in range(m):\n",
        "        y_logistic_regression.append(1/(1 + np.exp(-z[i])))       \n",
        "    return y_logistic_regression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPA11Brb8dZS",
        "colab_type": "text"
      },
      "source": [
        "## 3. Generate the `Cost Function` with `Gradient Descent` method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3eyeKqM8hIF",
        "colab_type": "text"
      },
      "source": [
        "### Generate the `objective function`\n",
        "\n",
        "Define the `degree of regularization` by the `control parameter`, $\\lambda$:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\lambda_1 = 0.000001, \\text{  for over-fitting} \\\\\n",
        "\\lambda_2 = 0.001, \\text{  for just-right} \\\\\n",
        "\\lambda_3 = 0.1, \\text{  for under-fitting}\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITLkuya6lvOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lambda1 = 0.000001\n",
        "lambda2 = 0.001\n",
        "lambda3 = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i8FKsXxlZSF",
        "colab_type": "text"
      },
      "source": [
        "Define the following `objective function` with a `regularization term`.\n",
        "\n",
        "\\begin{equation*}\n",
        "J(\\theta) = \\frac{1}{m}\\sum_{i = 1}^m[-l^{(i)}log(\\sigma(g(x^{(i)}, y^{(i)}; \\theta))) - (1 - l^{(i)})log(1 - \\sigma(g(x^{(i)}, y^{(i)}; \\theta)))] + \\frac{\\lambda}{2}\\sum_{i = 0}^9\\sum_{j = 0}^9\\theta_{i, j}^2\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLaUUmEpBWC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def objective_function(lambda_value, weight, y_logistic_regression):\n",
        "    error = []\n",
        "    regularization = 0\n",
        "    for i in range(10):\n",
        "        for j in range(10):\n",
        "            regularization = regularization + (weight[10 * i + j] ** 2)\n",
        "    regularization = (lambda_value / 2) * regularization\n",
        "    for k in range(m):\n",
        "        error.append((-label[k]) * np.log(y_logistic_regression[k]) - (1 - label[k]) * np.log(1 - y_logistic_regression[k]))\n",
        "    return (sum(error) / m) + regularization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwYNY2pI9XSL",
        "colab_type": "text"
      },
      "source": [
        "### Generate the `gradient descent`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvHAlub1_KUH",
        "colab_type": "text"
      },
      "source": [
        "Define the `learning rate`.\n",
        "\n",
        "\\begin{equation*}\n",
        "\\alpha  = 1\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smtm_inGFG1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky1NhF8Z9aym",
        "colab_type": "text"
      },
      "source": [
        "Define the following `gradient descent`.\n",
        "\n",
        "\\begin{equation*}\n",
        "\\theta_{i,j}^{(t+1)} := \\theta_{i,j}^{(t)} - \\alpha[\\frac{1}{m}\\sum_{i = 1}^m(\\sigma(g(x^{(i)}, y^{(i)}; \\theta^{(t)})) - l^{(i)})\\frac{\\partial g(x^{(i)}, y^{(i)}; \\theta^{(t)})}{\\partial \\theta_{i,j}} + \\lambda\\theta_{i,j}^{(t)}], \\quad\\text{for all $i, j$}, \\\\\n",
        "\\text{where,}\\quad\\frac{\\partial g(x^{(i)}, y^{(i)}; \\theta^{(t)})}{\\partial \\theta_{i,j}} = \\frac{\\partial\\sum_{i = 0}^9\\sum_{j = 0}^9\\theta_{i, j}x^iy^j}{\\partial \\theta_{i,j}} = \\frac{\\partial \\theta_{0,0}x^0y^0}{\\partial \\theta_{i,j}} + \\frac{\\partial \\theta_{0,1}x^0y^1}{\\partial \\theta_{i,j}} + ... + \\frac{\\partial \\theta_{9,9}x^9y^9}{\\partial \\theta_{i,j}}\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B5bXSBNFK0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient_descent(lambda_value, weight, y_logistic_regression):\n",
        "    weight_error = []\n",
        "    for i in range(100):\n",
        "        weight_error.append([])\n",
        "    weightPrime = []\n",
        "    for i in range(10):\n",
        "        for j in range(10):\n",
        "            for k in range(m):\n",
        "                weight_error[10 * i + j].append((y_logistic_regression[k] - label[k]) * (x_train[k] ** i) * (y_train[k] ** j))\n",
        "    for i in range(10):\n",
        "        for j in range(10):\n",
        "            weightPrime.append((1 - learning_rate * lambda_value) * weight[10 * i + j] - learning_rate * (sum(weight_error[10 * i + j]) / m))\n",
        "    return weightPrime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTQ5fNon_luS",
        "colab_type": "text"
      },
      "source": [
        "## 4. `Train` the input data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmCtCARLAJiS",
        "colab_type": "text"
      },
      "source": [
        "Define the initial `weight` and `offset`$(\\theta_{0,0}^{(0)}, \\theta_{0,1}^{(0)}, \\theta_{0,2}^{(0)}, ..., \\theta_{9,9}^{(0)})$:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\theta_{0,0}^{(0)} = \\theta_{0,1}^{(0)} = \\theta_{0,2}^{(0)} = ... = \\theta_{9,9}^{(0)} = 1\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdrJq6v6Fyg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight1 = []\n",
        "weight1.append([])\n",
        "for i in range(100):\n",
        "    weight1[0].append(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-pzvIy2M5y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight2 = []\n",
        "weight2.append([])\n",
        "for i in range(100):\n",
        "    weight2[0].append(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk3D70eeM8yd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight3 = []\n",
        "weight3.append([])\n",
        "for i in range(100):\n",
        "    weight3[0].append(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le6QhgTxG5Ur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cost_convergence = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKT5lGy2A5V8",
        "colab_type": "text"
      },
      "source": [
        "`Train` the `input data` with the `logistic regression` function above with the `gradient descent`. \\\\\n",
        "Find optimal parameters $\\theta$ using the `traing data`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqg-AemPG92m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = m\n",
        "sigma1 = []\n",
        "sigma2 = []\n",
        "sigma3 = []\n",
        "cost1 = []\n",
        "cost2 = []\n",
        "cost3 = []\n",
        "i = 0\n",
        "# print(logistic_regression(weight[i], offset[i]))\n",
        "# print(objective_function(logistic_regression(weight[i], offset[i])))\n",
        "sigma1.append(logistic_regression(weight1[i]))\n",
        "sigma2.append(logistic_regression(weight2[i]))\n",
        "sigma3.append(logistic_regression(weight3[i]))\n",
        "cost1.append(objective_function(lambda1, weight1[i], sigma1[i]))\n",
        "cost2.append(objective_function(lambda2, weight2[i], sigma2[i]))\n",
        "cost3.append(objective_function(lambda3, weight3[i], sigma3[i]))\n",
        "# print(j)\n",
        "\n",
        "while i < epoch:\n",
        "    i = i + 1\n",
        "\n",
        "#    print(k)\n",
        "    weight1.append(gradient_descent(lambda1, weight1[i - 1], sigma1[i - 1]))\n",
        "    weight2.append(gradient_descent(lambda2, weight2[i - 1], sigma2[i - 1]))\n",
        "    weight3.append(gradient_descent(lambda3, weight3[i - 1], sigma3[i - 1]))\n",
        "\n",
        "#    print('weight: ', weight)\n",
        "#    print('offset: ', offset)\n",
        "\n",
        "    sigma1.append(logistic_regression(weight1[i]))\n",
        "    sigma2.append(logistic_regression(weight2[i]))\n",
        "    sigma3.append(logistic_regression(weight3[i]))\n",
        "#    print('sigma: ', sigma)\n",
        "#    print(offset[k])\n",
        "#    print(round(j[k - 1], 2))\n",
        "    cost1.append(objective_function(lambda1, weight1[i], sigma1[i]))\n",
        "    cost2.append(objective_function(lambda2, weight2[i], sigma2[i]))\n",
        "    cost3.append(objective_function(lambda3, weight3[i], sigma3[i]))\n",
        "#    print('j: ', j)\n",
        "    if cost1[i] == cost1[i - 1]:\n",
        "        if cost2[i] == cost2[i - 1]:\n",
        "            if cost3[i] == cost3[i - 1]:\n",
        "                cost_convergence1.append(i)\n",
        "\n",
        "cost_convergence.append(epoch)\n",
        "\n",
        "# print(theta_convergence)\n",
        "# print(cost_convergence)\n",
        "# print('sigma: ', sigma)\n",
        "# print('j: ', j)\n",
        "# print('weight: ', weight)\n",
        "# print('offset: ', offset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB3-M51hBWvL",
        "colab_type": "text"
      },
      "source": [
        "## 5. Compute the `training accuracy`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDCv6bcBBg7T",
        "colab_type": "text"
      },
      "source": [
        "Compute the `final training accuracy` in `number (%)` with varying values of the `regularization parameter` $\\lambda$.\n",
        "\\begin{equation}\n",
        "accuracy\\ (\\%) = \\frac{\\text{number of correct predictions}}{\\text{total number of predictions}} \\times 100\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd9xOkHaMjLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_cost_minimum1 = cost1.index(min(cost1))\n",
        "index_cost_minimum2 = cost2.index(min(cost2))\n",
        "index_cost_minimum3 = cost3.index(min(cost3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz3jJn8j11A7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy1 = []\n",
        "i = 0\n",
        "for i in range(epoch):\n",
        "    correct_predictions = 0\n",
        "    for j in range(m):\n",
        "        if sigma1[i][j] == 0.5:\n",
        "            correct_predictions = correct_predictions + 1\n",
        "        else:\n",
        "            if sigma1[i][j] < 0.5:\n",
        "                if label[j] == 0:\n",
        "                    correct_predictions = correct_predictions + 1\n",
        "            else:\n",
        "                if label[j] == 1:\n",
        "                    correct_predictions = correct_predictions + 1\n",
        "    accuracy1.append((correct_predictions / m) * 100)\n",
        "# print(index_minimum)\n",
        "index_accuracy_maximum1 = accuracy1.index(max(accuracy1))\n",
        "# print(index_accuracy_maximum)\n",
        "# print(accuracy[index_accuracy_maximum])\n",
        "# print(accuracy[index_minimum-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IfDTyGlR50W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy2 = []\n",
        "i = 0\n",
        "for i in range(epoch):\n",
        "    correct_predictions = 0\n",
        "    for j in range(m):\n",
        "        if sigma2[i][j] == 0.5:\n",
        "            correct_predictions = correct_predictions + 1\n",
        "        else:\n",
        "            if sigma2[i][j] < 0.5:\n",
        "                if label[j] == 0:\n",
        "                    correct_predictions = correct_predictions + 1\n",
        "            else:\n",
        "                if label[j] == 1:\n",
        "                    correct_predictions = correct_predictions + 1\n",
        "    accuracy2.append((correct_predictions / m) * 100)\n",
        "# print(index_minimum)\n",
        "index_accuracy_maximum2 = accuracy2.index(max(accuracy2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBIM4Bm4SL37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy3 = []\n",
        "i = 0\n",
        "for i in range(epoch):\n",
        "    correct_predictions = 0\n",
        "    for j in range(m):\n",
        "        if sigma3[i][j] == 0.5:\n",
        "            correct_predictions = correct_predictions + 1\n",
        "        else:\n",
        "            if sigma3[i][j] < 0.5:\n",
        "                if label[j] == 0:\n",
        "                    correct_predictions = correct_predictions + 1\n",
        "            else:\n",
        "                if label[j] == 1:\n",
        "                    correct_predictions = correct_predictions + 1\n",
        "    accuracy3.append((correct_predictions / m) * 100)\n",
        "# print(index_minimum)\n",
        "index_accuracy_maximum3 = accuracy3.index(max(accuracy3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QnL_hZ6xUrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(sigma1[0])\n",
        "#print(sigma1[1])\n",
        "#print(sigma1[index_accuracy_maximum1])\n",
        "#print(sigma1[index_minimum-1])\n",
        "#print(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnS8zk_SxOWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(accuracy1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsekNLQJCU4T",
        "colab_type": "text"
      },
      "source": [
        "## 6. Visualize the `Classifier`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_c79LIbaCaCL",
        "colab_type": "text"
      },
      "source": [
        "Generate the `Classifier`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToMQM-UzZ1EF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(weight1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMOGxLLFDK1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classifier1(x, y):\n",
        "    optimal_g1 = 0\n",
        "    for i in range(10):\n",
        "        for j in range(10):\n",
        "            optimal_g1 = optimal_g1 + weight1[epoch][10 * i + j] * (x ** i) * (y ** j)\n",
        "    return optimal_g1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyuhAeY2UTZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classifier2(x, y):\n",
        "    optimal_g2 = 0\n",
        "    for i in range(10):\n",
        "        for j in range(10):\n",
        "            optimal_g2 = optimal_g2 + weight2[epoch][10 * i + j] * (x ** i) * (y ** j)\n",
        "    return optimal_g2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK6s1LHrUT-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classifier3(x, y):\n",
        "    optimal_g3 = 0\n",
        "    for i in range(10):\n",
        "        for j in range(10):\n",
        "            optimal_g3 = optimal_g3 + weight3[epoch][10 * i + j] * (x ** i) * (y ** j)\n",
        "    return optimal_g3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxoFNYszCdwj",
        "colab_type": "text"
      },
      "source": [
        "Visualize the obtained `classifier`, where the `boundary` of the `classifier` is defined by $\\{(x, y) | \\sigma(g(x, y ; \\theta)) = 0.5\\} = \\{(x, y) | g(x, y ; \\theta) = 0\\}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClQs5nLNvKbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "x = np.arange(-1, 1.25, 0.01)\n",
        "y = np.arange(-1, 1.25, 0.01)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "z1 = classifier1(X, Y)\n",
        "z2 = classifier2(X, Y)\n",
        "z3 = classifier3(X, Y)\n",
        "\n",
        "CS = plt.contour(X, Y, z1, [0], colors='red')\n",
        "CS = plt.contour(X, Y, z2, [0], colors='green')\n",
        "CS = plt.contour(X, Y, z3, [0], colors='blue')\n",
        "CS.clabel()\n",
        "plt.scatter(pointX0, pointY0, c='b')\n",
        "plt.scatter(pointX1, pointY1, c='r')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7KprHVQDhY3",
        "colab_type": "text"
      },
      "source": [
        "## 7. **Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqRkLfC5Dlpq",
        "colab_type": "text"
      },
      "source": [
        "### 1. **Plot the average image**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4ysZpDTDojS",
        "colab_type": "text"
      },
      "source": [
        "Plot the `average images` of the `same label` for `each digit` arrange the subplots in `2x5 array` for the 10 average images and present the `label` at the `title` of each subplot in the `increasing order` of the label.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyyRWqECQaxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.scatter(pointX0, pointY0, c='b')\n",
        "plt.scatter(pointX1, pointY1, c='r')\n",
        "plt.tight_layout()\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMDeilIRDuS2",
        "colab_type": "text"
      },
      "source": [
        "### 2. **Present the output of the neural network with random weights**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuqmpAX-w96y",
        "colab_type": "text"
      },
      "source": [
        "Consider a `neural network` with a `fully connected layer` using a `logistic unit` without a `bias`. \\\\\n",
        "Assign `random values` from the `normal distribution` $\\mathcal{N}(0, 1)$ with `mean` 0 and `standard deviation` 1 to the `weights` of the `fully connected layer` using a `logistic unit` without a `bias`. \\\\\n",
        "Compute the `forward propagation` and take the `average` of the `output values` for the `images` of the `same label`.\n",
        "Present the `average values` for `each label` in the `increasing order` of the `label`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EpsSm9ow880",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "x_cost1 = np.arange(0, cost_convergence[0])\n",
        "x_cost2 = np.arange(0, cost_convergence[0])\n",
        "x_cost3 = np.arange(0, cost_convergence[0])\n",
        "plt.xlabel('t (iteration)')\n",
        "plt.ylabel('J(theta)')\n",
        "\n",
        "plt.plot(x_cost1, cost1[:cost_convergence[0]], color = 'red', label = 'over-fitting error')\n",
        "plt.plot(x_cost2, cost2[:cost_convergence[0]], color = 'green', label = 'just-right error')\n",
        "plt.plot(x_cost3, cost3[:cost_convergence[0]], color = 'blue', label = 'under-fitting error')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}