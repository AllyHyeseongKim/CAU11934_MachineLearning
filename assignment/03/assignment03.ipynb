{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment03.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMXI+Wo+lYE3fay6Bu3Kemd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AllyHyeseongKim/CAU11934_MachineLarning/blob/master/assignment/03/assignment03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYUl9qFDln6i",
        "colab_type": "text"
      },
      "source": [
        "# Assignment03: Visualization of Gradient Descent algorithm based on Linear Regression problem\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NGz5gZFl6Nw",
        "colab_type": "text"
      },
      "source": [
        "## 1. Load the input data (CSV file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9NcHIKxnqCi",
        "colab_type": "text"
      },
      "source": [
        "### Mount the google drive "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od_Z7j02ni1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62uPXb0NovaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd gdrive/My Drive/Colab Notebooks/Machine Learning/assignment03"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTnVBGX9o6zA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E377ghAnpEd8",
        "colab_type": "text"
      },
      "source": [
        "### Load the Data\n",
        "\n",
        "Load a set of data points $\\{ (x^{(i)}, y^{(i)}) \\}$ from the given `CSV file` (`'data.csv'`). \\\\\n",
        "Plot the set of points that are loaded from `'data.csv'` file (in `black color`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOk6KpUnkLX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "path = 'data.csv'\n",
        "data = np.genfromtxt(path, delimiter = ',')\n",
        "\n",
        "m = len(data)\n",
        "x_train = data[:, 0]\n",
        "y_train = data[:, 1]\n",
        "\n",
        "plt.figure(figsize = (8, 8))\n",
        "plt.scatter(x_train, y_train, alpha = 0.3, c = 'k')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCSO81CFRRB8",
        "colab_type": "text"
      },
      "source": [
        "## 2. Generate the Linear Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ4DMsxRTKRB",
        "colab_type": "text"
      },
      "source": [
        "### Generate the `linear regression`\n",
        "\n",
        "Define the following `Linear Model`.\n",
        "\n",
        "\\begin{equation*}\n",
        "h_\\theta(x) = \\theta_0 + \\theta_1 x,\n",
        "\\quad\\quad \\text{where $\\theta = (\\theta_0, \\theta_1)$ and $\\theta_0, \\theta_1âˆˆ R$}\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-ozIIxxTQPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_regression(weight, offset):\n",
        "    y_linear_regression = []\n",
        "    for i in range(m):\n",
        "        y_linear_regression.append(offset + weight * x_train[i])\n",
        "    return y_linear_regression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE9lImlSTUF7",
        "colab_type": "text"
      },
      "source": [
        "## 3. Generate the `Cost Function` with `Gradient Descent` method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO_gSh89Tcl_",
        "colab_type": "text"
      },
      "source": [
        "### Generate the `objective function`\n",
        "\n",
        "Define the following `objective function`.\n",
        "\n",
        "\\begin{equation*}\n",
        "J(\\theta_0, \\theta_1) = \\frac{1}{2m}\\sum_{i = 1}^m(\\theta_0 + \\theta_1x^{(i)} - y^{(i)})^2\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1BXKFb_UOER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def objective_function(y_linear_regression):\n",
        "    error = []\n",
        "    for i in range(m):\n",
        "        error.append(y_linear_regression[i] - y_train[i])\n",
        "    return sum(error) ** 2 / (2 * m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWl7iOPyUU4X",
        "colab_type": "text"
      },
      "source": [
        "### Generate the `gradient descent`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOJK3s-HUZRR",
        "colab_type": "text"
      },
      "source": [
        "Define the following `gradient descent`.\n",
        "\n",
        "\\begin{equation*}\n",
        "\\theta_0^{(t+1)} := \\theta_0^{(t)} - \\alpha\\frac{1}{m}\\sum_{i = 1}^m(h_\\theta(x^{(i)}) - y^{(i)}) \\\\\n",
        "\\theta_1^{(t+1)} := \\theta_1^{(t)} - \\alpha\\frac{1}{m}\\sum_{i = 1}^m(h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sR0kfH9Ultj",
        "colab_type": "text"
      },
      "source": [
        "Define the `learning rate`.\n",
        "\n",
        "\\begin{equation*}\n",
        "\\alpha  = 0.035\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDimYIrQUpeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.035"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB8G6GpCUrIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient_descent(weight, offset, y_linear_regression):\n",
        "    offset_error = []\n",
        "    for i in range(m):\n",
        "        offset_error.append(y_linear_regression[i] - y_train[i])\n",
        "    offset = offset - learning_rate * sum(offset_error) / m\n",
        "    weight_error = []\n",
        "    for i in range(m):\n",
        "        weight_error.append((y_linear_regression[i] - y_train[i]) * x_train[i])\n",
        "    weight = weight - learning_rate * sum(weight_error) / m\n",
        "    return weight, offset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQhxDPs1UtgC",
        "colab_type": "text"
      },
      "source": [
        "## 4. `Train` the input data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zifxGPQGUzqf",
        "colab_type": "text"
      },
      "source": [
        "Define the initial `weight`$(\\theta_1^{(0)})$ and `offset`$(\\theta_0^{(0)})$.\n",
        "\n",
        "\\begin{equation*}\n",
        "\\theta_0^{(0)}  = -30, \\theta_1^{(0)}  = -30\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKpNtqT1UyXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight = []\n",
        "offset = []\n",
        "weight.append(-30)\n",
        "offset.append(-30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eogOi7nU2LJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cost_convergence = []\n",
        "theta_convergence = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNNrnx8_U5Fp",
        "colab_type": "text"
      },
      "source": [
        "`Train` the `input data` with the `linear regression` function above with the `gradient descent`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jCGzfwOU7xZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h = []\n",
        "j = []\n",
        "i = 0\n",
        "# print(linear_regression(weight[0], offset[0]))\n",
        "# print(objective_function(linear_regression(weight[0], offset[0])))\n",
        "h.append(linear_regression(weight[i], offset[i]))\n",
        "j.append(objective_function(linear_regression(weight[i], offset[i])))\n",
        "# print(j)\n",
        "\n",
        "while i < m:\n",
        "    i = i + 1\n",
        "#    print(i)\n",
        "#    print(weight, offset, j, h)\n",
        "    weight.append(gradient_descent(weight[i - 1], offset[i - 1], h[i - 1])[0])\n",
        "    offset.append(gradient_descent(weight[i - 1], offset[i - 1], h[i - 1])[1])\n",
        "    h.append(linear_regression(weight[i], offset[i]))\n",
        "#    print(offset[i])\n",
        "#    print(round(j[i - 1], 2))\n",
        "    j.append(objective_function(linear_regression(weight[i], offset[i])))\n",
        "    if round(j[i], 1) == round(j[i - 1],1):\n",
        "        cost_convergence.append(i)\n",
        "    if round(weight[i], 1) == round(weight[i - 1],1):\n",
        "        if (round(offset[i], 1) == round(offset[i - 1],1)):\n",
        "            theta_convergence.append(i)\n",
        "\n",
        "\n",
        "# x_out = np.arange(0, m + 1)\n",
        "# plt.plot(x_out, j, color = 'blue')\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoW2XXXaU_-V",
        "colab_type": "text"
      },
      "source": [
        "# 5. Generate the Output `Linear Model`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QszVU3HmVB3y",
        "colab_type": "text"
      },
      "source": [
        "Find the lowest cost value of the `Objective Function`, $J(\\theta)$, to find the `optimimal` result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNlooLU8VD0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_minimum = j.index(min(j))\n",
        "# print(index_minimum)\n",
        "x = np.arange(-15, 15)\n",
        "y_linear_model = weight[index_minimum] * x + offset[index_minimum]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYaOjIUdVFM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize = (8, 8))\n",
        "plt.scatter(x_train, y_train, alpha = 0.5, c = 'k')\n",
        "plt.plot(x, y_linear_model, color = 'red')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e_cilpGWGG6",
        "colab_type": "text"
      },
      "source": [
        "## 6. **Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM6mZAw0WI24",
        "colab_type": "text"
      },
      "source": [
        "### 1. **Input points**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQpiILt8WpUG",
        "colab_type": "text"
      },
      "source": [
        "Plot a set of `points` $\\{ (x^{(i)}, y^{(i)}) \\}$ that are loaded from `'data.csv'` file (in `black color`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRh6GBd0y7BP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize = (8, 8))\n",
        "plt.scatter(x_train, y_train, alpha = 0.8, c = 'k')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLTOJVbqWLFc",
        "colab_type": "text"
      },
      "source": [
        "### 2. **Linear regression result**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B401uRsDWyh3",
        "colab_type": "text"
      },
      "source": [
        "Plot a set of `points` $\\{ (x^{(i)}, y^{(i)}) \\}$ that are loaded from `'data.csv'` file (in `black color`). \\\\\n",
        "Plot a `straight line` obtained by the `optimal` `linear regression` based on the given set of points (in `red color`). \\\\\n",
        "The estimated `straight line` (`linear function`) is superimposed on the set of points.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E6nTAFvy9vQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize = (8, 8))\n",
        "plt.scatter(x_train, y_train, alpha = 0.5, c = 'k')\n",
        "plt.plot(x, y_linear_model, color = 'red')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RrdNtUfWR1s",
        "colab_type": "text"
      },
      "source": [
        "### 3. **Plot the energy surface**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oGrKGvWXJBV",
        "colab_type": "text"
      },
      "source": [
        "Plot the `energy surface` $(\\theta_0, \\theta_1, J(\\theta_0, \\theta_1)$ with the range of variables $\\theta_0 = [-30 : 0.1 : 30]$ and $\\theta_1 = [-30 : 0.1 : 30]$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRMm2hX6WWQV",
        "colab_type": "text"
      },
      "source": [
        "### 4. **Plot the gradient descent path on the energy surface**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vaXbPXDXTKK",
        "colab_type": "text"
      },
      "source": [
        "Plot the `energy surface` $(\\theta_0, \\theta_1, J(\\theta_0, \\theta_1)$ with the range of variables $\\theta_0 = [-30 : 0.1 : 30]$ and $\\theta_1 = [-30 : 0.1 : 30]$. \\\\\n",
        "Plot the `energy value` with the updated variables $\\theta_0^{(t)}$ and $\\theta_1^{(t)}$ at each `gradient descent` step on the `energy surface`. \\\\\n",
        "The initial condition is used by $\\theta_0^{(0)} = -30$ and $\\theta_1^{(0)} = -30$. \\\\ \n",
        "The `gradient descent` is performed until the `convergence` is achieved. \\\\\n",
        "The `gradient descent` `path` is superimposed on the `energy surface`.\n"
      ]
    }
  ]
}